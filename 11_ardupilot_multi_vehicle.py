#!/usr/bin/env python
"""
Pegasus ë“œë¡  ì°©ë¥™ ì‹œë®¬ë ˆì´ì…˜ (ê°•í™”í•™ìŠµ ëª¨ë¸ ì‚¬ìš©) - ê°œì„  ë²„ì „
ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ë§ˆì»¤ ì¸ì‹ ì‹œ ìœ„ì¹˜ ì¶œë ¥ ê°•í™”
2. ë“œë¡  ì¹˜ìš°ì¹¨ ë¬¸ì œ í•´ê²° (ì¢Œí‘œê³„ ë³€í™˜ ìˆ˜ì •)
3. ì½”ë“œ í’ˆì§ˆ ê°œì„  ë° ì•ˆì •ì„± í–¥ìƒ
"""

import carb
from isaacsim import SimulationApp

# Isaac Sim ì‹œì‘
simulation_app = SimulationApp({"headless": False})

import omni.timeline
import omni
from omni.isaac.core.world import World
import torch
import numpy as np
from scipy.spatial.transform import Rotation

from pegasus.simulator.params import ROBOTS, SIMULATION_ENVIRONMENTS
from pegasus.simulator.logic.vehicles.multirotor import Multirotor, MultirotorConfig
from pegasus.simulator.logic.interface.pegasus_interface import PegasusInterface
from pegasus.simulator.logic.backends.backend import Backend

from pxr import Sdf, UsdShade, UsdGeom, Gf, UsdLux

# Stable-Baselines3 (ê°•í™”í•™ìŠµ)
try:
    from stable_baselines3 import PPO
    RL_AVAILABLE = True
except ImportError:
    RL_AVAILABLE = False
    print("[WARN] stable-baselines3 not available. Install: pip install stable-baselines3")

# OpenCV (ArUco ê°ì§€)
try:
    import cv2
    import cv2.aruco as aruco
    ARUCO_AVAILABLE = True
except ImportError:
    ARUCO_AVAILABLE = False
    print("[WARN] OpenCV not available")


class RLDroneLandingController(Backend):
    """ê°•í™”í•™ìŠµ ê¸°ë°˜ ë“œë¡  ì°©ë¥™ ì œì–´ê¸° (Pegasus Backend)"""

    # ============================================================
    # â˜…â˜…â˜… íŠœë‹ íŒŒë¼ë¯¸í„° (ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!) â˜…â˜…â˜…
    # ============================================================

    # --- ë””ë²„ê¹… ëª¨ë“œ ---
    DEBUG_MODE = True           # Trueë¡œ ì„¤ì •í•˜ë©´ ë§¤ ìŠ¤í… ìƒì„¸ ì¶œë ¥

    # --- ArUco ì‚¬ìš© ì—¬ë¶€ ---
    USE_ARUCO = False           # False: ground truth ì‚¬ìš©, True: ArUco ê²€ì¶œ ì‚¬ìš©

    # --- ì¶”ë ¥ ê´€ë ¨ ---
    THRUST_SCALE = 1.0           # ì „ì²´ ì¶”ë ¥ ìŠ¤ì¼€ì¼ (1.0 = ì›ë³¸)
    THRUST_OFFSET = 0.0          # ì¶”ë ¥ ì˜¤í”„ì…‹ (0 = ì›ë³¸, IsaacLabê³¼ ë™ì¼)

    # --- í† í¬/íšŒì „ ê´€ë ¨ (action ì¶œë ¥ ê°ì‡ ) ---
    ROLL_SCALE = 1.0             # Roll (ì¢Œìš° ê¸°ìš¸ê¸°) ê°ì‡  (1.0 = ì›ë³¸)
    PITCH_SCALE = 1.0            # Pitch (ì•ë’¤ ê¸°ìš¸ê¸°) ê°ì‡  (1.0 = ì›ë³¸)
    YAW_SCALE = 1.0              # Yaw (íšŒì „) ê°ì‡  (1.0 = ì›ë³¸)

    # --- XY ì´ë™ ê°ì‡  (observation ì…ë ¥ ìŠ¤ì¼€ì¼) ---
    XY_GOAL_SCALE = 1.0          # XY ëª©í‘œ ê±°ë¦¬ ê°ì‡  (1.0 = ì›ë³¸)
    Z_GOAL_SCALE = 0.3           # Z ëª©í‘œ ê±°ë¦¬ ê°ì‡  (ì‘ì„ìˆ˜ë¡ í•˜ê°• ëŠë¦¼)

    # --- ì°©ë¥™ ì¡°ê±´ ---
    XY_THRESHOLD = 0.2           # XY ì˜¤ì°¨ê°€ ì´ ì´í•˜ì¼ ë•Œë§Œ í•˜ê°• (m)

    # --- ì†ë„ ê°ì‡  (observation ì…ë ¥ ìŠ¤ì¼€ì¼) ---
    VEL_SCALE = 1.0              # ì†ë„ observation ìŠ¤ì¼€ì¼ (1.0 = ì›ë³¸)
    ANG_VEL_SCALE = 1.0          # ê°ì†ë„ observation ìŠ¤ì¼€ì¼ (1.0 = ì›ë³¸, ì‚¬ìš© ì•ˆí•¨)

    # --- ë¬¼ë¦¬ íŒŒë¼ë¯¸í„° ---
    IRIS_MASS = 1.5              # Iris ë“œë¡  ì§ˆëŸ‰ (kg)
    TRAIN_MASS = 0.033           # í•™ìŠµ ë•Œ ì‚¬ìš©í•œ Crazyflie ì§ˆëŸ‰ (kg)
    TRAIN_THRUST_TO_WEIGHT = 1.9 # í•™ìŠµ ë•Œ thrust-to-weight ratio
    TRAIN_MOMENT_SCALE = 0.002   # í•™ìŠµ ë•Œ moment scale (Nm)

    # --- í† í¬ ìŠ¤ì¼€ì¼ ì˜¤ë²„ë¼ì´ë“œ ---
    TORQUE_MULTIPLIER = 1.0      # í† í¬ ì „ì²´ ë°°ìœ¨ (ìë™ê³„ì‚° í›„ ì¶”ê°€ ì¡°ì •)

    # ============================================================

    def __init__(self, rover_initial_pos, rover_velocity, model_path, device="cuda", detection_callback=None):
        # Backend ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(config=None)

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.rl_device = device

        # ë¡œë²„ ì„¤ì •
        self.rover_pos = np.array(rover_initial_pos, dtype=np.float32)
        self.rover_vel = np.array(rover_velocity, dtype=np.float32)

        # RL ëª¨ë¸ ë¡œë“œ
        if RL_AVAILABLE:
            print(f"[RL] Loading model from: {model_path}")
            self.model = PPO.load(model_path, device=device)
            print(f"[RL] Model loaded successfully on {device}")
        else:
            raise ImportError("stable-baselines3 not installed!")

        # ë¬¼ë¦¬ íŒŒë¼ë¯¸í„°
        self.gravity = 9.81

        # íŠœë‹ íŒŒë¼ë¯¸í„° ì¶œë ¥
        print("\n" + "="*60)
        print("â˜… RL Controller íŠœë‹ íŒŒë¼ë¯¸í„° â˜…")
        print("="*60)
        print(f"  THRUST_SCALE:    {self.THRUST_SCALE}")
        print(f"  THRUST_OFFSET:   {self.THRUST_OFFSET}")
        print(f"  ROLL_SCALE:      {self.ROLL_SCALE}")
        print(f"  PITCH_SCALE:     {self.PITCH_SCALE}")
        print(f"  YAW_SCALE:       {self.YAW_SCALE}")
        print(f"  XY_GOAL_SCALE:   {self.XY_GOAL_SCALE}")
        print(f"  Z_GOAL_SCALE:    {self.Z_GOAL_SCALE}")
        print(f"  XY_THRESHOLD:    {self.XY_THRESHOLD}m (XY ì •ë ¬ í›„ í•˜ê°•)")
        print(f"  VEL_SCALE:       {self.VEL_SCALE}")
        print(f"  ANG_VEL_SCALE:   {self.ANG_VEL_SCALE}")
        print(f"  TORQUE_MULTIPLIER: {self.TORQUE_MULTIPLIER}")
        print(f"  DEBUG_MODE:      {self.DEBUG_MODE}")
        print(f"  USE_ARUCO:       {self.USE_ARUCO}")
        if not self.USE_ARUCO:
            print(f"  âš ï¸  Ground truth ëª¨ë“œ! ì‹¤ì œ ë¡œë²„ ìœ„ì¹˜ ì‚¬ìš©")
        print("="*60 + "\n")
        
        # ìƒíƒœ
        self.dt = 0.01
        self.time = 0.0
        self.estimated_rover_pos = None
        self.detection_callback = detection_callback
        self._state = None
        
        # ì°©ë¥™ ìƒíƒœ
        self.phase = "APPROACH"
        self.approach_height = 5.5
        self.landing_height = 0.75
        self.current_target_height = self.approach_height  # í˜„ì¬ ëª©í‘œ ë†’ì´
        
        # ëª©í‘œ ìœ„ì¹˜ (world frame)
        self.desired_pos_w = np.array(rover_initial_pos, dtype=np.float32)
        self.desired_pos_w[2] = self.landing_height
        
        # ë””ë²„ê·¸ ì¹´ìš´í„°
        self._obs_debug_count = 0
        self._action_debug_count = 0
        
    def update(self, dt: float):
        """Backend í•„ìˆ˜ ë©”ì„œë“œ"""
        self.dt = dt
        self.time += dt

        # ëª©í‘œ XY ìœ„ì¹˜ ì—…ë°ì´íŠ¸
        if self.USE_ARUCO and self.estimated_rover_pos is not None:
            # ArUco ê²€ì¶œ ê²°ê³¼ ì‚¬ìš©
            self.desired_pos_w[:2] = self.estimated_rover_pos[:2]
        else:
            # Ground truth ì‚¬ìš© (ë””ë²„ê¹…ìš©)
            self.desired_pos_w[:2] = self.rover_pos[:2]

        # â˜…â˜…â˜… ì¡°ê±´ë¶€ í•˜ê°•: XY ì •ë ¬ í›„ì—ë§Œ í•˜ê°• â˜…â˜…â˜…
        if self._state is not None:
            drone_pos = np.array(self._state.position)
            xy_error = np.linalg.norm(drone_pos[:2] - self.desired_pos_w[:2])

            if xy_error < self.XY_THRESHOLD:
                # XY ì •ë ¬ë¨ â†’ í•˜ê°•
                descent_rate = 0.5  # m/s
                self.current_target_height = max(
                    self.landing_height,
                    self.current_target_height - descent_rate * dt
                )
                if self.phase != "LANDING":
                    self.phase = "LANDING"
                    print(f"[Phase] LANDING - XY error: {xy_error:.2f}m < {self.XY_THRESHOLD}m")
            else:
                # XY ë¯¸ì •ë ¬ â†’ ë†’ì´ ìœ ì§€
                if self.phase != "APPROACH":
                    self.phase = "APPROACH"
                    print(f"[Phase] APPROACH - XY error: {xy_error:.2f}m > {self.XY_THRESHOLD}m")

        self.desired_pos_w[2] = self.current_target_height

    def set_rover_pos(self, pos):
        """Appì—ì„œ ë¡œë²„ ìœ„ì¹˜ë¥¼ ì§ì ‘ ì„¤ì • (syncìš©)"""
        self.rover_pos[:] = pos
    
    def input_reference(self):
        """RL ëª¨ë¸ë¡œ ì•¡ì…˜ ê²°ì • í›„ 4ê°œ ë¡œí„° ì†ë„ ë°˜í™˜"""
        # í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        state = self._get_vehicle_state()
        
        # Observation êµ¬ì„± (Isaac Labê³¼ ë™ì¼í•œ 16ì°¨ì›)
        obs = self._construct_observation(state)
        
        # RL ëª¨ë¸ë¡œ ì•¡ì…˜ ì˜ˆì¸¡
        action, _states = self.model.predict(obs, deterministic=True)
        
        # NumPyë¡œ ë³€í™˜
        if isinstance(action, torch.Tensor):
            action = action.cpu().numpy()
        action = action.flatten()
        
        # ì•¡ì…˜ì„ ë¡œí„° ì†ë„ë¡œ ë³€í™˜
        rotor_velocities = self._action_to_rotor_velocities(action, state)
        
        return rotor_velocities.tolist()
    
    def _construct_observation(self, state):
        """Isaac Lab í™˜ê²½ê³¼ â˜…â˜…â˜… ì™„ì „íˆ ë™ì¼í•œ â˜…â˜…â˜… 16ì°¨ì› observation êµ¬ì„±

        drone_landing_env.pyì™€ 1:1 ëŒ€ì‘:
        - R.inv().apply() ì‚¬ìš© (scipy Rotation ë©”ì„œë“œ)
        - ê°ì†ë„ëŠ” world frame ê·¸ëŒ€ë¡œ ì‚¬ìš©!
        - ì¤‘ë ¥ì€ [0, 0, -gravity] ì‚¬ìš© (ì •ê·œí™” ì•ˆí•¨)
        """

        # ë“œë¡  ìƒíƒœ
        pos = np.array(state.position, dtype=np.float32)
        lin_vel = np.array(state.linear_velocity, dtype=np.float32)
        ang_vel = np.array(state.angular_velocity, dtype=np.float32)

        # â˜…â˜…â˜… í•µì‹¬: Pegasus attitudeëŠ” [x,y,z,w] ìˆœì„œ â˜…â˜…â˜…
        # IsaacLabì˜ drone_landing_env.pyì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        quat_xyzw = np.array(state.attitude, dtype=np.float32)

        # Rotation ê°ì²´ ìƒì„± (scipyëŠ” [x,y,z,w] ìˆœì„œ)
        R = Rotation.from_quat(quat_xyzw)

        # â˜…â˜…â˜… 1. ë“œë¡  ì†ë„ (body frame) - R.inv().apply() ì‚¬ìš©! â˜…â˜…â˜…
        lin_vel_b = R.inv().apply(lin_vel)
        lin_vel_b = lin_vel_b * self.VEL_SCALE

        # â˜…â˜…â˜… 2. ê°ì†ë„ - IsaacLabì—ì„œëŠ” world frame ê·¸ëŒ€ë¡œ ì‚¬ìš©! â˜…â˜…â˜…
        # drone_landing_env.py: obsì— ang_vel ê·¸ëŒ€ë¡œ ë„£ìŒ (ë³€í™˜ ì•ˆí•¨)
        ang_vel_obs = ang_vel  # body frame ë³€í™˜ ì•ˆí•¨!

        # â˜…â˜…â˜… 3. ì¤‘ë ¥ ë°©í–¥ (body frame) - ìŠ¤ì¼€ì¼ ìœ ì§€! â˜…â˜…â˜…
        gravity_world = np.array([0, 0, -self.gravity], dtype=np.float32)
        gravity_b = R.inv().apply(gravity_world)

        # â˜…â˜…â˜… 4. ëª©í‘œ ìœ„ì¹˜ (body frame) â˜…â˜…â˜…
        goal_rel_world = self.desired_pos_w - pos
        desired_pos_b = R.inv().apply(goal_rel_world)

        # XY/Z ìŠ¤ì¼€ì¼ ì ìš© (í•„ìš”ì‹œ)
        desired_pos_b[0] = desired_pos_b[0] * self.XY_GOAL_SCALE
        desired_pos_b[1] = desired_pos_b[1] * self.XY_GOAL_SCALE
        desired_pos_b[2] = desired_pos_b[2] * self.Z_GOAL_SCALE

        # â˜…â˜…â˜… 5. ìƒëŒ€ ì†ë„ (body frame) â˜…â˜…â˜…
        rel_vel_world = lin_vel - self.rover_vel
        rel_vel_b = R.inv().apply(rel_vel_world)
        rel_vel_b = rel_vel_b * self.VEL_SCALE

        # â˜…â˜…â˜… 6. Yaw ê°ë„ - IsaacLabê³¼ ë™ì¼í•œ ê³„ì‚° â˜…â˜…â˜…
        quat_wxyz = np.array([quat_xyzw[3], quat_xyzw[0], quat_xyzw[1], quat_xyzw[2]])
        current_yaw = np.arctan2(
            2.0 * (quat_wxyz[0]*quat_wxyz[3] + quat_wxyz[1]*quat_wxyz[2]),
            1.0 - 2.0 * (quat_wxyz[2]**2 + quat_wxyz[3]**2)
        )

        # ë””ë²„ê¹… ì¶œë ¥
        if (self.DEBUG_MODE or self._obs_debug_count < 5) and self._obs_debug_count % 50 == 1:
            print(f"\n{'='*70}")
            print(f"ğŸ“Š Observation Debug (step {self._obs_debug_count})")
            print(f"{'='*70}")
            print(f"  Drone pos (world):    [{pos[0]:6.2f}, {pos[1]:6.2f}, {pos[2]:6.2f}]")
            print(f"  Rover pos (world):    [{self.rover_pos[0]:6.2f}, {self.rover_pos[1]:6.2f}, {self.rover_pos[2]:6.2f}]")
            print(f"  Desired pos (world):  [{self.desired_pos_w[0]:6.2f}, {self.desired_pos_w[1]:6.2f}, {self.desired_pos_w[2]:6.2f}]")
            print(f"  Goal rel (world):     [{goal_rel_world[0]:6.2f}, {goal_rel_world[1]:6.2f}, {goal_rel_world[2]:6.2f}] (norm: {np.linalg.norm(goal_rel_world):.2f}m)")
            print(f"  Goal rel (body):      [{desired_pos_b[0]:6.2f}, {desired_pos_b[1]:6.2f}, {desired_pos_b[2]:6.2f}]")
            print(f"  Lin vel (body):       [{lin_vel_b[0]:6.2f}, {lin_vel_b[1]:6.2f}, {lin_vel_b[2]:6.2f}]")
            print(f"  Ang vel (world!):     [{ang_vel_obs[0]:6.2f}, {ang_vel_obs[1]:6.2f}, {ang_vel_obs[2]:6.2f}]")
            print(f"  Gravity (body):       [{gravity_b[0]:6.2f}, {gravity_b[1]:6.2f}, {gravity_b[2]:6.2f}]")
            print(f"  Yaw: {np.degrees(current_yaw):6.1f}Â°")
        self._obs_debug_count += 1

        # â˜…â˜…â˜… 16ì°¨ì› ì—°ê²° - IsaacLabê³¼ ì™„ì „íˆ ë™ì¼í•œ ìˆœì„œ! â˜…â˜…â˜…
        obs = np.concatenate([
            lin_vel_b,        # 3: ì„ ì†ë„ (body) - R.inv().apply(vel)
            ang_vel_obs,      # 3: ê°ì†ë„ (world!) - ë³€í™˜ ì•ˆí•¨!
            gravity_b,        # 3: ì¤‘ë ¥ ë°©í–¥ (body)
            desired_pos_b,    # 3: ëª©í‘œ ìœ„ì¹˜ (body)
            rel_vel_b,        # 3: ìƒëŒ€ ì†ë„ (body)
            [current_yaw]     # 1: yaw ê°ë„
        ])

        return obs.astype(np.float32)
    
    def _action_to_rotor_velocities(self, action, state):
        """RL ì•¡ì…˜ì„ ë¡œí„° ì†ë„ë¡œ ë³€í™˜"""
        # ì•¡ì…˜ í´ë¦¬í•‘
        action = np.clip(action, -1.0, 1.0)
        
        # ì›ë³¸ ì•¡ì…˜ ì €ì¥ (ë””ë²„ê¹…ìš©)
        original_action = action.copy()

        # ì•¡ì…˜ ì¶”ì¶œ
        thrust_action = action[0]
        roll_action = action[1]
        pitch_action = action[2]
        yaw_action = action[3]
        
        # ëª¨ë©˜íŠ¸ ìŠ¤ì¼€ì¼ ì ìš©
        roll_scaled = roll_action * self.ROLL_SCALE
        pitch_scaled = pitch_action * self.PITCH_SCALE
        yaw_scaled = yaw_action * self.YAW_SCALE
        moments_scaled = np.array([roll_scaled, pitch_scaled, yaw_scaled])

        # ì§ˆëŸ‰ë¹„ ê³„ì‚°
        mass_ratio = self.IRIS_MASS / self.TRAIN_MASS

        # ì¶”ë ¥ ë³€í™˜
        thrust_ratio = self.TRAIN_THRUST_TO_WEIGHT * (thrust_action + 1.0) / 2.0
        thrust_ratio = thrust_ratio * self.THRUST_SCALE + self.THRUST_OFFSET
        thrust_force = thrust_ratio * self.IRIS_MASS * self.gravity

        # í† í¬ ë³€í™˜
        torques = moments_scaled * self.TRAIN_MOMENT_SCALE * mass_ratio * self.TORQUE_MULTIPLIER

        if (self.DEBUG_MODE or self._action_debug_count < 5) and self._action_debug_count % 50 == 1:
            print(f"\n{'='*70}")
            print(f"ğŸ® Action Debug (step {self._action_debug_count})")
            print(f"{'='*70}")
            print(f"  Raw action (RL):  [{original_action[0]:6.3f}, {original_action[1]:6.3f}, {original_action[2]:6.3f}, {original_action[3]:6.3f}]")
            print(f"  After invert:     [{thrust_action:6.3f}, {roll_action:6.3f}, {pitch_action:6.3f}, {yaw_action:6.3f}]")
            print(f"  Scaled moments:   [{roll_scaled:6.3f}, {pitch_scaled:6.3f}, {yaw_scaled:6.3f}]")
            print(f"  thrust_force:     {thrust_force:6.2f} N (hover: {self.IRIS_MASS * self.gravity:.2f} N)")
            print(f"  torques (Nm):     [{torques[0]:7.4f}, {torques[1]:7.4f}, {torques[2]:7.4f}]")
        self._action_debug_count += 1

        # Pegasus ë‚´ì¥ í•¨ìˆ˜ë¡œ ë¡œí„° ì†ë„ ë³€í™˜
        if self.vehicle:
            rotor_velocities = self.vehicle.force_and_torques_to_velocities(thrust_force, torques)
            return np.array(rotor_velocities)
        else:
            return np.array([500.0, 500.0, 500.0, 500.0])
    
    def update_estimator(self, marker_pos_world):
        """íƒœê·¸ ê°ì§€ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        self.estimated_rover_pos = marker_pos_world
        
        # â˜…â˜…â˜… ë§ˆì»¤ ì¸ì‹ ì‹œ ìœ„ì¹˜ ì¶œë ¥ ê°•í™” â˜…â˜…â˜…
        if hasattr(self, '_state') and self._state is not None:
            drone_pos = np.array(self._state.position)
            error_xy = np.linalg.norm(drone_pos[:2] - marker_pos_world[:2])
            error_z = abs(drone_pos[2] - marker_pos_world[2])
            
            # print(f"\n{'='*70}")
            # print(f"ğŸ¯ ë§ˆì»¤ ì¸ì‹ ì„±ê³µ!")
            # print(f"{'='*70}")
            # print(f"  ë§ˆì»¤ ìœ„ì¹˜ (world): [{marker_pos_world[0]:6.2f}, {marker_pos_world[1]:6.2f}, {marker_pos_world[2]:6.2f}]")
            # print(f"  ë“œë¡  ìœ„ì¹˜ (world): [{drone_pos[0]:6.2f}, {drone_pos[1]:6.2f}, {drone_pos[2]:6.2f}]")
            # print(f"  XY ì˜¤ì°¨: {error_xy:5.2f}m  |  Z ì˜¤ì°¨: {error_z:5.2f}m")
            # print(f"{'='*70}\n")
    
    def update_sensor(self, sensor_type: str, sensor_data: dict):
        """ì„¼ì„œ ë°ì´í„° ìˆ˜ì‹ """
        pass
    
    def update_state(self, state: dict):
        """ë“œë¡  ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self._state = state
    
    def start(self):
        """Backend ì‹œì‘"""
        print("[RL Controller] Started")
        print(f"[RL Controller] Model device: {self.rl_device}")
    
    def stop(self):
        """Backend ì¤‘ì§€"""
        print(f"[RL Controller] Stopped - Final phase: {self.phase}")
    
    def reset(self):
        """Backend ë¦¬ì…‹"""
        self.time = 0.0
        self.phase = "APPROACH"
        self.estimated_rover_pos = None
        self._obs_debug_count = 0
        self._action_debug_count = 0
        print("[RL Controller] Reset")
    
    def update_graphical_sensor(self, sensor_data: dict):
        """ê·¸ë˜í”½ ì„¼ì„œ ì—…ë°ì´íŠ¸"""
        pass
        
    def _get_vehicle_state(self):
        """í˜„ì¬ ë“œë¡  ìƒíƒœ ë°˜í™˜"""
        if hasattr(self, '_state') and self._state is not None:
            return self._state
        
        # ê¸°ë³¸ê°’
        class DummyState:
            def __init__(self):
                self.position = np.zeros(3, dtype=np.float32)
                self.linear_velocity = np.zeros(3, dtype=np.float32)
                self.attitude = np.array([0, 0, 0, 1], dtype=np.float32)
                self.angular_velocity = np.zeros(3, dtype=np.float32)
        
        return DummyState()


class PegasusRLLandingApp:
    """Pegasus RL ì°©ë¥™ ì‹œë®¬ë ˆì´ì…˜ ì•±"""
    
    def __init__(self, model_path):
        self.timeline = omni.timeline.get_timeline_interface()
        self.pg = PegasusInterface()
        self.pg._world = World(**self.pg._world_settings)
        self.world = self.pg.world
        
        # í™˜ê²½ ë¡œë“œ
        self.pg.load_environment(SIMULATION_ENVIRONMENTS["Curved Gridroom"])
        
        # ë¡œë²„ ì„¤ì •
        self.rover_pos = np.array([0.0, 0.0, 0.375], dtype=np.float32)  # íë¸Œ 0.75 / 2
        self.rover_vel = np.array([0.0, 0.0, 0.0], dtype=np.float32)
        
        # RL ì œì–´ê¸° ìƒì„±
        self.controller = RLDroneLandingController(
            self.rover_pos.copy(),
            self.rover_vel.copy(),
            model_path=model_path,
            device="cuda" if torch.cuda.is_available() else "cpu",
            detection_callback=self._on_detection
        )
        
        # ë“œë¡  ìƒì„±
        config = MultirotorConfig()
        config.backends = [self.controller]
        
        initial_pos = [
            -1.5,
            -1.5,
            5.5
        ]
        
        print(f"[Init] Drone starting at: {initial_pos}")
        print(f"[Init] Rover at: {self.rover_pos}")
        
        self.drone = Multirotor(
            "/World/Drone",
            ROBOTS['Iris'],
            0,
            initial_pos,
            Rotation.from_euler("XYZ", [0, 0, 0], degrees=True).as_quat(),
            config=config
        )
        
        # ì¡°ëª… ì¶”ê°€
        self._add_lighting()
        
        # ë¡œë²„ ìƒì„±
        self._create_rover()
        
        # ì¹´ë©”ë¼ ì„¤ì •
        self._setup_camera()
        
        # ArUco ê°ì§€ê¸° ì´ˆê¸°í™”
        if ARUCO_AVAILABLE:
            self._init_aruco()
        
        self.world.reset()
        
        # ìƒíƒœ
        self.step_count = 0
        self.detection_count = 0
        self.last_saved_frame = -1
        self.last_detection_time = 0.0
        
        print("\n[Verification] Checking drone initial position...")
        drone_state = self.drone.state
        actual_pos = np.array([drone_state.position[0], drone_state.position[1], drone_state.position[2]])
        print(f"  Expected: {initial_pos}")
        print(f"  Actual:   {actual_pos}")
        
        if not np.allclose(actual_pos, initial_pos, atol=0.1):
            print(f"  âš ï¸  Position mismatch detected!")
        else:
            print(f"  âœ“ Position correct!")
        
    def _add_lighting(self):
        """ê°•í™”ëœ ì¡°ëª… ì‹œìŠ¤í…œ"""
        stage = omni.usd.get_context().get_stage()
        
        # DistantLight
        distant_light_path = "/World/DistantLight"
        distant_light = UsdLux.DistantLight.Define(stage, distant_light_path)
        distant_light.CreateIntensityAttr(5000.0)
        distant_light.CreateColorAttr(Gf.Vec3f(1.0, 1.0, 0.95))
        distant_light.CreateAngleAttr(0.53)
        
        xform = UsdGeom.Xformable(distant_light)
        xform.ClearXformOpOrder()
        rotate_op = xform.AddRotateXYZOp()
        rotate_op.Set(Gf.Vec3f(-45, 45, 0))
        
        # DomeLight
        dome_light_path = "/World/DomeLight"
        dome_light = UsdLux.DomeLight.Define(stage, dome_light_path)
        dome_light.CreateIntensityAttr(1000.0)
        dome_light.CreateColorAttr(Gf.Vec3f(0.9, 0.95, 1.0))
        
        print("[Lighting] Added: DistantLight (5000 lux) + DomeLight (1000 lux)")
        
    def _create_rover(self):
        """AprilTag ë¡œë²„ ìƒì„±"""
        stage = omni.usd.get_context().get_stage()
        from pxr import UsdGeom, UsdPhysics

        rover_path = "/World/Rover"
        xform = UsdGeom.Xform.Define(stage, rover_path)

        # Cube - 1.5ë°° í¬ê¸° (0.5 â†’ 0.75)
        cube_path = rover_path + "/Cube"
        cube = UsdGeom.Cube.Define(stage, cube_path)
        cube.GetSizeAttr().Set(0.75)  # 1.5ë°° í¬ê¸°

        # íšŒìƒ‰ ì¬ì§ˆ
        cube_mtl_path = Sdf.Path(cube_path + "_Material")
        cube_mtl = UsdShade.Material.Define(stage, cube_mtl_path)
        cube_shader = UsdShade.Shader.Define(stage, cube_mtl_path.AppendPath("Shader"))
        cube_shader.CreateIdAttr("UsdPreviewSurface")
        cube_shader.CreateInput("diffuseColor", Sdf.ValueTypeNames.Color3f).Set(Gf.Vec3f(0.5, 0.5, 0.5))
        cube_shader.CreateInput("roughness", Sdf.ValueTypeNames.Float).Set(0.8)
        cube_mtl.CreateSurfaceOutput().ConnectToSource(cube_shader.ConnectableAPI(), "surface")
        UsdShade.MaterialBindingAPI(cube.GetPrim()).Bind(cube_mtl)

        # â˜…â˜…â˜… ë¬¼ë¦¬: Kinematic Bodyë¡œ ë³€ê²½ (ë– ì˜¤ë¥´ì§€ ì•Šê²Œ) â˜…â˜…â˜…
        rigid_api = UsdPhysics.RigidBodyAPI.Apply(xform.GetPrim())
        rigid_api.CreateKinematicEnabledAttr(True)  # Kinematic = ë¬¼ë¦¬ ì˜í–¥ ì•ˆ ë°›ìŒ
        collision_api = UsdPhysics.CollisionAPI.Apply(cube.GetPrim())

        # ì´ˆê¸° ìœ„ì¹˜
        xform_ops = xform.AddTranslateOp()
        xform_ops.Set(Gf.Vec3d(float(self.rover_pos[0]), float(self.rover_pos[1]), float(self.rover_pos[2])))
        
        # AprilTag í…ìŠ¤ì²˜
        self._add_apriltag_texture()
        
        # ë¡œë²„ ìœ„ ì¡°ëª…
        light_path = rover_path + "/SpotLight"
        spot_light = UsdLux.SphereLight.Define(stage, light_path)
        spot_light.CreateIntensityAttr(2000.0)
        spot_light.CreateRadiusAttr(0.05)
        spot_light.CreateColorAttr(Gf.Vec3f(1.0, 1.0, 1.0))
        
        light_xform = UsdGeom.Xformable(spot_light)
        light_translate = light_xform.AddTranslateOp()
        light_translate.Set(Gf.Vec3d(0, 0, 0.5))
        
        print(f"[Rover] Created at {self.rover_pos}")
        
    def _add_apriltag_texture(self):
        """AprilTag í…ìŠ¤ì²˜ ìƒì„±"""
        stage = omni.usd.get_context().get_stage()
        
        mesh_path = "/World/Rover/TagMesh"
        mesh = UsdGeom.Mesh.Define(stage, mesh_path)

        # íƒœê·¸ í¬ê¸°ë„ 1.5ë°° (0.3 â†’ 0.45)
        half = 0.45
        mesh.GetPointsAttr().Set([
            Gf.Vec3f(-half, -half, 0),
            Gf.Vec3f(half, -half, 0),
            Gf.Vec3f(half, half, 0),
            Gf.Vec3f(-half, half, 0)
        ])
        mesh.GetFaceVertexCountsAttr().Set([4])
        mesh.GetFaceVertexIndicesAttr().Set([0, 1, 2, 3])
        mesh.GetNormalsAttr().Set([Gf.Vec3f(0, 0, 1)] * 4)
        mesh.SetNormalsInterpolation("vertex")

        texcoords = UsdGeom.PrimvarsAPI(mesh).CreatePrimvar(
            "st", Sdf.ValueTypeNames.TexCoord2fArray, UsdGeom.Tokens.vertex
        )
        texcoords.Set([Gf.Vec2f(0, 0), Gf.Vec2f(1, 0), Gf.Vec2f(1, 1), Gf.Vec2f(0, 1)])

        xform = UsdGeom.Xformable(mesh)
        translate_op = xform.AddTranslateOp()
        translate_op.Set(Gf.Vec3d(0, 0, 0.376))  # íë¸Œ ë†’ì´ 0.75/2 = 0.375 + ì•½ê°„
        
        # AprilTag ì´ë¯¸ì§€ ìƒì„±
        tag_image_path = self._generate_apriltag_image()
        
        # ë°œê´‘ ì¬ì§ˆ
        mtl_path = Sdf.Path(mesh_path + "_Material")
        mtl = UsdShade.Material.Define(stage, mtl_path)
        
        shader = UsdShade.Shader.Define(stage, mtl_path.AppendPath("Shader"))
        shader.CreateIdAttr("UsdPreviewSurface")
        shader.CreateInput("roughness", Sdf.ValueTypeNames.Float).Set(0.1)
        
        st_reader = UsdShade.Shader.Define(stage, mtl_path.AppendPath("stReader"))
        st_reader.CreateIdAttr("UsdPrimvarReader_float2")
        st_reader.CreateInput("varname", Sdf.ValueTypeNames.Token).Set("st")
        
        diffuse_tex = UsdShade.Shader.Define(stage, mtl_path.AppendPath("DiffuseTexture"))
        diffuse_tex.CreateIdAttr("UsdUVTexture")
        diffuse_tex.CreateInput("file", Sdf.ValueTypeNames.Asset).Set(tag_image_path)
        diffuse_tex.CreateInput("st", Sdf.ValueTypeNames.Float2).ConnectToSource(
            st_reader.ConnectableAPI(), "result"
        )
        
        shader.CreateInput("diffuseColor", Sdf.ValueTypeNames.Color3f).ConnectToSource(
            diffuse_tex.ConnectableAPI(), "rgb"
        )
        shader.CreateInput("emissiveColor", Sdf.ValueTypeNames.Color3f).ConnectToSource(
            diffuse_tex.ConnectableAPI(), "rgb"
        )
        
        mtl.CreateSurfaceOutput().ConnectToSource(shader.ConnectableAPI(), "surface")
        UsdShade.MaterialBindingAPI(mesh.GetPrim()).Bind(mtl)
        
        print(f"[Rover] AprilTag texture added: {tag_image_path}")
        
    def _generate_apriltag_image(self):
        """AprilTag ì´ë¯¸ì§€ ìƒì„±"""
        if not ARUCO_AVAILABLE:
            return "/tmp/dummy_tag.png"
        
        aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_36h11)
        tag_size = 512
        border_bits = 1
        
        tag_image = np.zeros((tag_size, tag_size), dtype=np.uint8)
        tag_image = aruco.generateImageMarker(aruco_dict, 0, tag_size, tag_image, border_bits)
        
        full_size = 600
        full_image = np.ones((full_size, full_size), dtype=np.uint8) * 255
        offset = (full_size - tag_size) // 2
        full_image[offset:offset+tag_size, offset:offset+tag_size] = tag_image
        
        output_path = "/tmp/apriltag_36h11_id0.png"
        cv2.imwrite(output_path, full_image)
        print(f"[AprilTag] Generated: {output_path}")
        
        return output_path
        
    def _setup_camera(self):
        """ë“œë¡ ì— ì¹´ë©”ë¼ ë¶€ì°©"""
        stage = omni.usd.get_context().get_stage()
        
        camera_path = "/World/Drone/body/Camera"
        camera_prim = UsdGeom.Camera.Define(stage, camera_path)
        
        camera_prim.GetFocalLengthAttr().Set(8.0)
        camera_prim.GetHorizontalApertureAttr().Set(60.0)
        camera_prim.GetVerticalApertureAttr().Set(33.75)
        camera_prim.GetFocusDistanceAttr().Set(1000.0)
        camera_prim.GetFStopAttr().Set(0.0)
        camera_prim.GetClippingRangeAttr().Set(Gf.Vec2f(0.01, 10000.0))
        
        xform = UsdGeom.Xformable(camera_prim)
        xform.ClearXformOpOrder()
        translate_op = xform.AddTranslateOp()
        translate_op.Set(Gf.Vec3d(0, 0, -0.15))
        
        if ARUCO_AVAILABLE:
            try:
                import omni.replicator.core as rep
                self.render_product = rep.create.render_product(camera_path, (1280, 720))
                self.annotator = rep.AnnotatorRegistry.get_annotator("rgb")
                self.annotator.attach([self.render_product])
                print("[Camera] 1280x720 @ 150Â° FOV")
            except Exception as e:
                print(f"[WARN] Camera setup failed: {e}")
                self.annotator = None
        
    def _init_aruco(self):
        """ArUco ê°ì§€ê¸° ì´ˆê¸°í™”"""
        img_w, img_h = 1280, 720
        fov_deg = 150.0
        self.fx = img_w / (2 * np.tan(np.radians(fov_deg / 2)))
        self.fy = self.fx
        self.cx = img_w / 2
        self.cy = img_h / 2
        
        self.camera_matrix = np.array([
            [self.fx, 0, self.cx],
            [0, self.fy, self.cy],
            [0, 0, 1]
        ], dtype=np.float32)
        self.dist_coeffs = np.zeros((5, 1), dtype=np.float32)
        
        self.aruco_dicts = {
            "DICT_APRILTAG_36h11": aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_36h11),
            "DICT_APRILTAG_25h9": aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_25h9),
            "DICT_APRILTAG_16h5": aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_16h5),
        }
        self.aruco_params = aruco.DetectorParameters()
        
        print(f"[ArUco] Initialized with camera matrix:")
        print(f"  fx={self.fx:.1f}, fy={self.fy:.1f}")
        print(f"  cx={self.cx:.1f}, cy={self.cy:.1f}")
        
    def _detect_aruco(self):
        """ArUco íƒœê·¸ ê°ì§€"""
        # if not ARUCO_AVAILABLE or not hasattr(self, 'annotator') or self.annotator is None:
        #     return
        
        # if self.step_count % 2 != 0:
        #     return
        
        try:
            image_data = self.annotator.get_data()
            
            if image_data is None:
                return
            
            if not isinstance(image_data, np.ndarray) or image_data.size == 0:
                return
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image_data.shape) == 3:
                gray = cv2.cvtColor(image_data[:, :, :3].astype(np.uint8), cv2.COLOR_RGB2GRAY)
                color_image = image_data[:, :, :3].astype(np.uint8).copy()
            else:
                gray = image_data.astype(np.uint8)
                color_image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
            
            # ê°ì§€
            corners, ids = None, None
            detected_dict_name = None
            for dict_name, aruco_dict in self.aruco_dicts.items():
                detector = aruco.ArucoDetector(aruco_dict, self.aruco_params)
                corners, ids, _ = detector.detectMarkers(gray)
                if ids is not None and len(ids) > 0:
                    detected_dict_name = dict_name
                    break
            
            vis_img = color_image.copy()
            
            if ids is not None and len(ids) > 0:
                aruco.drawDetectedMarkers(vis_img, corners, ids)
                
                # 3D ìì„¸ ì¶”ì •
                rvecs, tvecs = self._estimate_pose(corners, 0.6)
                
                if tvecs is not None and len(tvecs) > 0:
                    tvec = tvecs[0][0]

                    drone_state = self.drone.state
                    drone_pos = np.array(drone_state.position)
                    drone_quat = np.array(drone_state.attitude)

                    r = Rotation.from_quat(drone_quat)

                    # â˜…â˜…â˜… ì¹´ë©”ë¼â†’world ì¢Œí‘œ ë³€í™˜ ìˆ˜ì • â˜…â˜…â˜…
                    # ì¹´ë©”ë¼ ì¢Œí‘œê³„ (OpenCV): X=ì˜¤ë¥¸ìª½, Y=ì•„ë˜, Z=ì „ë°©(ê±°ë¦¬)
                    # ì¹´ë©”ë¼ê°€ ë“œë¡  ì•„ë˜ì—ì„œ ì•„ë˜ë¥¼ í–¥í•¨:
                    #   - ì¹´ë©”ë¼ Zì¶• â†’ ë“œë¡  -Zì¶• (ì•„ë˜)
                    #   - ì¹´ë©”ë¼ Xì¶• â†’ ë“œë¡  Yì¶• (ì˜¤ë¥¸ìª½)
                    #   - ì¹´ë©”ë¼ Yì¶• â†’ ë“œë¡  Xì¶• (ì•ìª½)
                    marker_in_body = np.array([
                        tvec[1],    # body X = camera Y
                        tvec[0],    # body Y = camera X
                        -tvec[2]    # body Z = -camera Z (ë§ˆì»¤ëŠ” ì•„ë˜ì— ìˆìœ¼ë¯€ë¡œ)
                    ])

                    # Body â†’ World ë³€í™˜
                    marker_in_world = drone_pos + r.apply(marker_in_body)

                    # ë””ë²„ê¹… ì¶œë ¥
                    if self.step_count % 100 == 0:
                        print(f"[ArUco] tvec: [{tvec[0]:.2f}, {tvec[1]:.2f}, {tvec[2]:.2f}]")
                        print(f"[ArUco] body: [{marker_in_body[0]:.2f}, {marker_in_body[1]:.2f}, {marker_in_body[2]:.2f}]")
                        print(f"[ArUco] world: [{marker_in_world[0]:.2f}, {marker_in_world[1]:.2f}, {marker_in_world[2]:.2f}]")
                        print(f"[ArUco] actual rover: [{self.rover_pos[0]:.2f}, {self.rover_pos[1]:.2f}, {self.rover_pos[2]:.2f}]")

                    self._on_detection(marker_in_world[:2])
                    
                    self.detection_count += 1
                    self.last_detection_time = self.step_count * 0.01
                    
                    cv2.drawFrameAxes(vis_img, self.camera_matrix, self.dist_coeffs, 
                                     rvecs[0].reshape(3,1), tvecs[0].reshape(3,1), 0.3)
            
            # ì‹­ìì„ 
            cv2.line(vis_img, (int(self.cx)-20, int(self.cy)), (int(self.cx)+20, int(self.cy)), (255,0,0), 2)
            cv2.line(vis_img, (int(self.cx), int(self.cy)-20), (int(self.cx), int(self.cy)+20), (255,0,0), 2)
            
            # ìƒíƒœ í…ìŠ¤íŠ¸
            num_markers = 0 if ids is None else len(ids)
            if num_markers > 0:
                status = f"Markers: {num_markers} ({detected_dict_name})"
                color = (0, 255, 0)
            else:
                status = "No markers detected"
                color = (0, 0, 255)
            
            cv2.putText(vis_img, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            # ì‹œê°„ ì •ë³´
            time_since_detection = self.step_count * 0.01 - self.last_detection_time
            time_text = f"Time: {self.step_count*0.01:.1f}s | Last detect: {time_since_detection:.1f}s ago"
            cv2.putText(vis_img, time_text, (10, vis_img.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            # ì´ë¯¸ì§€ ì €ì¥
            if self.step_count % 50 == 0 and self.step_count != self.last_saved_frame:
                output_path = f"/tmp/aruco_rl_{self.step_count:06d}.png"
                cv2.imwrite(output_path, vis_img)
                self.last_saved_frame = self.step_count
                if self.step_count % 200 == 0:
                    print(f"[Debug] Saved: {output_path}")
            
        except Exception as e:
            if self.step_count % 100 == 0:
                print(f"[WARN] Detection error: {e}")
    
    def _estimate_pose(self, corners, marker_size):
        """ë§ˆì»¤ 3D ìì„¸ ì¶”ì •"""
        marker_points = np.array([
            [-marker_size/2, marker_size/2, 0],
            [marker_size/2, marker_size/2, 0],
            [marker_size/2, -marker_size/2, 0],
            [-marker_size/2, -marker_size/2, 0]
        ], dtype=np.float32)
        
        rvecs, tvecs = [], []
        for corner in corners:
            retval, rvec, tvec = cv2.solvePnP(
                marker_points, corner, self.camera_matrix, self.dist_coeffs,
                None, None, False, cv2.SOLVEPNP_IPPE_SQUARE
            )
            if retval:
                rvecs.append(rvec.reshape(1, 3))
                tvecs.append(tvec.reshape(1, 3))
        
        if len(rvecs) == 0:
            return None, None
        return np.array(rvecs), np.array(tvecs)
    
    def _on_detection(self, marker_pos_xy):
        """íƒœê·¸ ê°ì§€ ì½œë°±"""
        full_pos = np.array([marker_pos_xy[0], marker_pos_xy[1], self.rover_pos[2]])
        self.controller.update_estimator(full_pos)
    
    def _update_rover(self, dt):
        """ë¡œë²„ ì´ë™"""
        stage = omni.usd.get_context().get_stage()
        rover_prim = stage.GetPrimAtPath("/World/Rover")

        if not rover_prim.IsValid():
            return

        self.rover_pos += self.rover_vel * dt

        # Controllerì—ë„ ë¡œë²„ ìœ„ì¹˜ ë™ê¸°í™”
        self.controller.set_rover_pos(self.rover_pos)

        xformable = UsdGeom.Xformable(rover_prim)
        translate_op = None
        for op in xformable.GetOrderedXformOps():
            if op.GetOpType() == UsdGeom.XformOp.TypeTranslate:
                translate_op = op
                break

        if translate_op:
            translate_op.Set(Gf.Vec3d(float(self.rover_pos[0]), float(self.rover_pos[1]), float(self.rover_pos[2])))
    
    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        self.timeline.play()
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™” ëŒ€ê¸°
        print("[Camera] Waiting for initialization (3 seconds)...")
        for _ in range(300):
            self.world.step(render=True)
            self.step_count += 1
        print("[Camera] âœ“ Ready!")
        
        while simulation_app.is_running():
            # ArUco ê°ì§€
            self._detect_aruco()
            
            # ë¡œë²„ ì—…ë°ì´íŠ¸
            self._update_rover(self.world.get_physics_dt())
            
            # ë¬¼ë¦¬ ìŠ¤í…
            self.world.step(render=True)
            self.step_count += 1
            
            # ìƒíƒœ ì¶œë ¥
            if self.step_count % 100 == 0:
                drone_state = self.drone.state
                drone_pos = np.array([drone_state.position[0], drone_state.position[1], drone_state.position[2]])
                rover_xy_error = np.linalg.norm(drone_pos[:2] - self.rover_pos[:2])
                
                # XY ë°©í–¥ ì˜¤ì°¨ ë¶„ì„
                xy_error_vector = drone_pos[:2] - self.rover_pos[:2]
                x_err = xy_error_vector[0]
                y_err = xy_error_vector[1]
                
                if self.controller.estimated_rover_pos is not None:
                    detection_status = "âœ“ Tracking"
                    tracking_error = np.linalg.norm(drone_pos[:2] - self.controller.estimated_rover_pos[:2])
                    tracking_info = f"Track err: {tracking_error:.2f}m"
                else:
                    detection_status = "âœ— No tag"
                    tracking_info = ""
                
                # â˜…â˜…â˜… ì¹˜ìš°ì¹¨ ê²½ê³  â˜…â˜…â˜…
                bias_warning = ""
                # if abs(y_err) > 0.5:
                #     if y_err > 0:
                #         bias_warning = "âš ï¸  ë“œë¡ ì´ +Y(ì˜¤ë¥¸ìª½)ìœ¼ë¡œ ì¹˜ìš°ì¹¨!"
                #     else:
                #         bias_warning = "âš ï¸  ë“œë¡ ì´ -Y(ì™¼ìª½)ìœ¼ë¡œ ì¹˜ìš°ì¹¨!"
                
                # if abs(x_err) > 0.5:
                #     if x_err > 0:
                #         bias_warning += " +X(ì•)ìœ¼ë¡œ ì¹˜ìš°ì¹¨!"
                #     else:
                #         bias_warning += " -X(ë’¤)ìœ¼ë¡œ ì¹˜ìš°ì¹¨!"
                
                # print(f"[{self.step_count*0.01:.1f}s] {detection_status} | "
                #       f"XY err: {rover_xy_error:.2f}m (X:{x_err:+.2f}, Y:{y_err:+.2f}) | "
                #       f"Height: {drone_pos[2]:.2f}m | "
                #       f"{tracking_info} | Detections: {self.detection_count} {bias_warning}")
        
        print(f"\n{'='*70}")
        print(f"[Summary] ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ")
        print(f"{'='*70}")
        print(f"  ì´ ê°ì§€ íšŸìˆ˜: {self.detection_count}")
        print(f"  ì´ í”„ë ˆì„: {self.step_count}")
        print(f"  ê°ì§€ìœ¨: {self.detection_count / max(1, self.step_count/2) * 100:.1f}%")
        print(f"  ë””ë²„ê·¸ ì´ë¯¸ì§€: /tmp/aruco_rl_*.png")
        print(f"{'='*70}\n")
        
        carb.log_warn("Simulation closing")
        self.timeline.stop()
        simulation_app.close()


def main():
    import sys
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
    else:
        model_path = "/home/rtx5080/s/ISAAC_LAB_DRONE/logs/sb3/Template-DroneLanding-v0/2026-01-20_15-52-16/model.zip"
    
    print(f"\n{'='*70}")
    print(f"RL ë“œë¡  ì°©ë¥™ ì‹œë®¬ë ˆì´ì…˜")
    print(f"{'='*70}")
    print(f"[Main] Model: {model_path}")
    print(f"\ní˜„ì¬ ì„¤ì •:")
    print(f"   DEBUG_MODE: {RLDroneLandingController.DEBUG_MODE}")
    print(f"   USE_ARUCO:  {RLDroneLandingController.USE_ARUCO}")
    if not RLDroneLandingController.USE_ARUCO:
        print(f"\n   Ground Truth ëª¨ë“œ:")
        print(f"   - ArUco ê²€ì¶œ ë¹„í™œì„±í™”")
        print(f"   - ì‹¤ì œ ë¡œë²„ ìœ„ì¹˜ë¥¼ ëª©í‘œë¡œ ì‚¬ìš©")
        print(f"   - Observationì´ ì˜¬ë°”ë¥¸ì§€ í…ŒìŠ¤íŠ¸ìš©")
    print(f"{'='*70}\n")
    
    # RL ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
    if not RL_AVAILABLE:
        print("[ERROR] stable-baselines3 not installed!")
        print("Install: pip install stable-baselines3")
        return
    
    app = PegasusRLLandingApp(model_path)
    app.run()


if __name__ == "__main__":
    main()